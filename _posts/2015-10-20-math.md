---
layout: post
title: Lagrange Duality and Max-Min Inequality
date: 2021-10-30
description: Relating Max-Min Inequality to the Lagrange Duality
---
In this post, we review the Lagrange Duality and give a min-max inequality based interpretation of the duality. We first describe the general optimization problem:
Given any optimization problem (\*) of the form:

$$
\rm\ minimize \rm\ f_{0}(x)
$$
$$
s.t. \rm\ \rm\  f_{i}(x) \leq 0, \; i=1,\ldots, m \\
h_{i}(x) = 0, \; i=1,\ldots,p
$$
The above problem can be convex problem, non-convex problem, or very well be NP-hard problem. We define the Lagrangian function $$L: \mathbb{R}^{n}\times \mathbb{R}^{m}\times \mathbb{R}^{p} \rightarrow \mathbb{R}$$ as follows:
$$
L(x, \mathbb{\lambda}, \mathbb{\nu}) = f_{0}(x) + \sum_{i=1}^{m}\lambda_{i}f_{i}(x) + \sum_{i=1}^{p}\nu_{i}h_{i}(x)
$$
And the Lagrangian dual function as $$g(\lambda, \nu) = \inf_{x}L(x, \mathbf{\lambda}, \mathbf{\nu})$$. Then, we have the following proposition:



You can also use `\begin{equation}...\end{equation}` instead of `$$` for display mode math.
MathJax will automatically number equations:

\begin{equation}
\label{eq:caushy-shwarz}
\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)
\end{equation}

and by adding `\label{...}` inside the equation environment, we can now refer to the equation using `\eqref`.

Note that MathJax 3 is [a major re-write of MathJax](https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html) that brought a significant improvement to the loading and rendering speed, which is now [on par with KaTeX](http://www.intmath.com/cg5/katex-mathjax-comparison.php).
